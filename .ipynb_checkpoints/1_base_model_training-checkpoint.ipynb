{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import models\n",
    "from validation import recall_m, precision_m, f1_m, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train,label_train=data.data_train()\n",
    "data_test,label_test=data.testing()\n",
    "data_marm,label_marm,data_marml_tl,label_marm_tl=data.marmousi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train input size = (15750, 50, 50, 2)\n",
      "train label size = (15750, 40)\n",
      "test input size = (3150, 50, 50, 2)\n",
      "test label size = (3150, 40)\n",
      "marmousi input size = (17325, 50, 50, 2)\n",
      "marmousi label size = (17325, 40)\n"
     ]
    }
   ],
   "source": [
    "print('train input size =',data_train.shape)\n",
    "print('train label size =',label_train.shape)\n",
    "\n",
    "print('test input size =',data_test.shape)\n",
    "print('test label size =',label_test.shape)\n",
    "\n",
    "print('marmousi input size =',data_marm.shape)\n",
    "print('marmousi label size =',label_marm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/packages/conda/envs/saigml/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/packages/conda/envs/saigml/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 64)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4718848   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 40)                5160      \n",
      "=================================================================\n",
      "Total params: 4,831,976\n",
      "Trainable params: 4,831,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##models.simple = two layers cnn \n",
    "##models.vgg16= vgg16 \n",
    "\n",
    "model=models.simple()\n",
    "#model=models.vgg16()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### for using multi gpu #####\n",
    "\n",
    "#from multi_gpu import multi_gpu_model\n",
    "#model = multi_gpu_model(model, gpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_decay(epoch):\n",
    "    initial_lr = 1e-4\n",
    "    max_epoch = 20\n",
    "\n",
    "    if epoch < max_epoch:\n",
    "        lr = initial_lr\n",
    "    else:\n",
    "        idecay = (epoch // max_epoch)\n",
    "        lr = initial_lr/(idecay * 2)\n",
    "    return lr\n",
    "\n",
    "###### declare check point ####### \n",
    "lr_sched = LearningRateScheduler(learning_rate_decay)\n",
    "model_checkpoint = ModelCheckpoint('CNN.hdf5', monitor='loss', verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/packages/conda/envs/saigml/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/packages/conda/envs/saigml/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15750 samples, validate on 3150 samples\n",
      "Epoch 1/100\n",
      "15750/15750 [==============================] - 6s 404us/step - loss: 3.3874 - acc: 0.2037 - val_loss: 3.3851 - val_acc: 0.1054\n",
      "Epoch 2/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 3.0494 - acc: 0.2363 - val_loss: 3.0384 - val_acc: 0.1270\n",
      "Epoch 3/100\n",
      "15750/15750 [==============================] - 1s 85us/step - loss: 2.6341 - acc: 0.2827 - val_loss: 2.6135 - val_acc: 0.2330\n",
      "Epoch 4/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 2.3044 - acc: 0.3318 - val_loss: 2.2478 - val_acc: 0.2514\n",
      "Epoch 5/100\n",
      "15750/15750 [==============================] - 1s 91us/step - loss: 2.0884 - acc: 0.3670 - val_loss: 2.1041 - val_acc: 0.2556\n",
      "Epoch 6/100\n",
      "15750/15750 [==============================] - 1s 90us/step - loss: 1.9279 - acc: 0.3942 - val_loss: 2.0619 - val_acc: 0.2632\n",
      "Epoch 7/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 1.8053 - acc: 0.4185 - val_loss: 2.0102 - val_acc: 0.2724\n",
      "Epoch 8/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 1.7211 - acc: 0.4342 - val_loss: 2.0464 - val_acc: 0.2597\n",
      "Epoch 9/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 1.6378 - acc: 0.4542 - val_loss: 2.0105 - val_acc: 0.2638\n",
      "Epoch 10/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 1.5670 - acc: 0.4594 - val_loss: 2.0705 - val_acc: 0.2644\n",
      "Epoch 11/100\n",
      "15750/15750 [==============================] - 1s 90us/step - loss: 1.4988 - acc: 0.4797 - val_loss: 2.0793 - val_acc: 0.2663\n",
      "Epoch 12/100\n",
      "15750/15750 [==============================] - 2s 96us/step - loss: 1.4436 - acc: 0.4921 - val_loss: 2.0967 - val_acc: 0.2610\n",
      "Epoch 13/100\n",
      "15750/15750 [==============================] - 1s 94us/step - loss: 1.4018 - acc: 0.4963 - val_loss: 2.1216 - val_acc: 0.2676\n",
      "Epoch 14/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 1.3442 - acc: 0.5130 - val_loss: 2.1561 - val_acc: 0.2654\n",
      "Epoch 15/100\n",
      "15750/15750 [==============================] - 1s 90us/step - loss: 1.2981 - acc: 0.5273 - val_loss: 2.1455 - val_acc: 0.2752\n",
      "Epoch 16/100\n",
      "15750/15750 [==============================] - 1s 94us/step - loss: 1.2654 - acc: 0.5335 - val_loss: 2.1547 - val_acc: 0.2752\n",
      "Epoch 17/100\n",
      "15750/15750 [==============================] - 1s 92us/step - loss: 1.2333 - acc: 0.5415 - val_loss: 2.1853 - val_acc: 0.2860\n",
      "Epoch 18/100\n",
      "15750/15750 [==============================] - 1s 86us/step - loss: 1.1918 - acc: 0.5500 - val_loss: 2.2722 - val_acc: 0.2819\n",
      "Epoch 19/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 1.1625 - acc: 0.5583 - val_loss: 2.2406 - val_acc: 0.2784\n",
      "Epoch 20/100\n",
      "15750/15750 [==============================] - 1s 91us/step - loss: 1.1344 - acc: 0.5650 - val_loss: 2.3624 - val_acc: 0.2692\n",
      "Epoch 21/100\n",
      "15750/15750 [==============================] - 2s 98us/step - loss: 1.1036 - acc: 0.5755 - val_loss: 2.3644 - val_acc: 0.2743\n",
      "Epoch 22/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 1.0880 - acc: 0.5723 - val_loss: 2.3525 - val_acc: 0.2797\n",
      "Epoch 23/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 1.0775 - acc: 0.5829 - val_loss: 2.3666 - val_acc: 0.2816\n",
      "Epoch 24/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 1.0675 - acc: 0.5816 - val_loss: 2.4040 - val_acc: 0.2730\n",
      "Epoch 25/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 1.0534 - acc: 0.5890 - val_loss: 2.4254 - val_acc: 0.2762\n",
      "Epoch 26/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 1.0392 - acc: 0.5938 - val_loss: 2.4645 - val_acc: 0.2746\n",
      "Epoch 27/100\n",
      "15750/15750 [==============================] - 2s 96us/step - loss: 1.0273 - acc: 0.5957 - val_loss: 2.4352 - val_acc: 0.2749\n",
      "Epoch 28/100\n",
      "15750/15750 [==============================] - 1s 89us/step - loss: 1.0105 - acc: 0.6048 - val_loss: 2.4716 - val_acc: 0.2797\n",
      "Epoch 29/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 1.0111 - acc: 0.6004 - val_loss: 2.5028 - val_acc: 0.2676\n",
      "Epoch 30/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.9952 - acc: 0.6078 - val_loss: 2.4859 - val_acc: 0.2765\n",
      "Epoch 31/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.9809 - acc: 0.6097 - val_loss: 2.5314 - val_acc: 0.2727\n",
      "Epoch 32/100\n",
      "15750/15750 [==============================] - 2s 96us/step - loss: 0.9643 - acc: 0.6145 - val_loss: 2.5204 - val_acc: 0.2759\n",
      "Epoch 33/100\n",
      "15750/15750 [==============================] - 1s 92us/step - loss: 0.9557 - acc: 0.6207 - val_loss: 2.5216 - val_acc: 0.2784\n",
      "Epoch 34/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.9414 - acc: 0.6243 - val_loss: 2.5658 - val_acc: 0.2794\n",
      "Epoch 35/100\n",
      "15750/15750 [==============================] - 1s 86us/step - loss: 0.9458 - acc: 0.6208 - val_loss: 2.5746 - val_acc: 0.2762\n",
      "Epoch 36/100\n",
      "15750/15750 [==============================] - 1s 89us/step - loss: 0.9270 - acc: 0.6298 - val_loss: 2.6091 - val_acc: 0.2778\n",
      "Epoch 37/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 0.9153 - acc: 0.6343 - val_loss: 2.6861 - val_acc: 0.2756\n",
      "Epoch 38/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 0.9035 - acc: 0.6359 - val_loss: 2.6190 - val_acc: 0.2670\n",
      "Epoch 39/100\n",
      "15750/15750 [==============================] - 1s 89us/step - loss: 0.9102 - acc: 0.6358 - val_loss: 2.6438 - val_acc: 0.2768\n",
      "Epoch 40/100\n",
      "15750/15750 [==============================] - 2s 99us/step - loss: 0.9000 - acc: 0.6362 - val_loss: 2.6369 - val_acc: 0.2740\n",
      "Epoch 41/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.8889 - acc: 0.6383 - val_loss: 2.7208 - val_acc: 0.2638\n",
      "Epoch 42/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.8827 - acc: 0.6439 - val_loss: 2.6873 - val_acc: 0.2676\n",
      "Epoch 43/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.8667 - acc: 0.6477 - val_loss: 2.7178 - val_acc: 0.2695\n",
      "Epoch 44/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.8637 - acc: 0.6465 - val_loss: 2.7666 - val_acc: 0.2705\n",
      "Epoch 45/100\n",
      "15750/15750 [==============================] - 2s 100us/step - loss: 0.8726 - acc: 0.6450 - val_loss: 2.7190 - val_acc: 0.2702\n",
      "Epoch 46/100\n",
      "15750/15750 [==============================] - 1s 89us/step - loss: 0.8631 - acc: 0.6489 - val_loss: 2.7367 - val_acc: 0.2676\n",
      "Epoch 47/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 0.8566 - acc: 0.6530 - val_loss: 2.7570 - val_acc: 0.2676\n",
      "Epoch 48/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 0.8511 - acc: 0.6507 - val_loss: 2.7676 - val_acc: 0.2708\n",
      "Epoch 49/100\n",
      "15750/15750 [==============================] - 1s 94us/step - loss: 0.8518 - acc: 0.6545 - val_loss: 2.7490 - val_acc: 0.2657\n",
      "Epoch 50/100\n",
      "15750/15750 [==============================] - 2s 96us/step - loss: 0.8333 - acc: 0.6613 - val_loss: 2.7954 - val_acc: 0.2648\n",
      "Epoch 51/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 0.8412 - acc: 0.6545 - val_loss: 2.8141 - val_acc: 0.2667\n",
      "Epoch 52/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.8359 - acc: 0.6580 - val_loss: 2.7913 - val_acc: 0.2644\n",
      "Epoch 53/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.8297 - acc: 0.6592 - val_loss: 2.8121 - val_acc: 0.2708\n",
      "Epoch 54/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.8223 - acc: 0.6632 - val_loss: 2.8217 - val_acc: 0.2670\n",
      "Epoch 55/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 0.8208 - acc: 0.6639 - val_loss: 2.8507 - val_acc: 0.2635\n",
      "Epoch 56/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.8226 - acc: 0.6638 - val_loss: 2.8651 - val_acc: 0.2654\n",
      "Epoch 57/100\n",
      "15750/15750 [==============================] - 1s 90us/step - loss: 0.8124 - acc: 0.6673 - val_loss: 2.8334 - val_acc: 0.2705\n",
      "Epoch 58/100\n",
      "15750/15750 [==============================] - 1s 90us/step - loss: 0.8189 - acc: 0.6668 - val_loss: 2.8162 - val_acc: 0.2660\n",
      "Epoch 59/100\n",
      "15750/15750 [==============================] - 1s 89us/step - loss: 0.8057 - acc: 0.6712 - val_loss: 2.8201 - val_acc: 0.2651\n",
      "Epoch 60/100\n",
      "15750/15750 [==============================] - 1s 93us/step - loss: 0.8047 - acc: 0.6698 - val_loss: 2.8416 - val_acc: 0.2587\n",
      "Epoch 61/100\n",
      "15750/15750 [==============================] - 1s 92us/step - loss: 0.7991 - acc: 0.6714 - val_loss: 2.8709 - val_acc: 0.2616\n",
      "Epoch 62/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 0.8021 - acc: 0.6735 - val_loss: 2.8763 - val_acc: 0.2600\n",
      "Epoch 63/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.7843 - acc: 0.6754 - val_loss: 2.9336 - val_acc: 0.2603\n",
      "Epoch 64/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 0.7840 - acc: 0.6757 - val_loss: 2.8904 - val_acc: 0.2692\n",
      "Epoch 65/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.7991 - acc: 0.6698 - val_loss: 2.8451 - val_acc: 0.2635\n",
      "Epoch 66/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.7910 - acc: 0.6751 - val_loss: 2.8979 - val_acc: 0.2622\n",
      "Epoch 67/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.7894 - acc: 0.6737 - val_loss: 2.9254 - val_acc: 0.2600\n",
      "Epoch 68/100\n",
      "15750/15750 [==============================] - 1s 90us/step - loss: 0.7845 - acc: 0.6751 - val_loss: 2.9138 - val_acc: 0.2587\n",
      "Epoch 69/100\n",
      "15750/15750 [==============================] - 1s 94us/step - loss: 0.7808 - acc: 0.6816 - val_loss: 2.9161 - val_acc: 0.2600\n",
      "Epoch 70/100\n",
      "15750/15750 [==============================] - 2s 100us/step - loss: 0.7735 - acc: 0.6779 - val_loss: 2.9384 - val_acc: 0.2619\n",
      "Epoch 71/100\n",
      "15750/15750 [==============================] - 1s 89us/step - loss: 0.7730 - acc: 0.6851 - val_loss: 2.9546 - val_acc: 0.2606\n",
      "Epoch 72/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 0.7750 - acc: 0.6833 - val_loss: 2.9484 - val_acc: 0.2632\n",
      "Epoch 73/100\n",
      "15750/15750 [==============================] - 1s 89us/step - loss: 0.7730 - acc: 0.6819 - val_loss: 2.9772 - val_acc: 0.2571\n",
      "Epoch 74/100\n",
      "15750/15750 [==============================] - 1s 89us/step - loss: 0.7692 - acc: 0.6852 - val_loss: 2.9890 - val_acc: 0.2622\n",
      "Epoch 75/100\n",
      "15750/15750 [==============================] - 2s 97us/step - loss: 0.7735 - acc: 0.6815 - val_loss: 2.9699 - val_acc: 0.2584\n",
      "Epoch 76/100\n",
      "15750/15750 [==============================] - 1s 95us/step - loss: 0.7680 - acc: 0.6811 - val_loss: 3.0150 - val_acc: 0.2603\n",
      "Epoch 77/100\n",
      "15750/15750 [==============================] - 1s 86us/step - loss: 0.7607 - acc: 0.6808 - val_loss: 3.0106 - val_acc: 0.2641\n",
      "Epoch 78/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.7579 - acc: 0.6895 - val_loss: 2.9763 - val_acc: 0.2660\n",
      "Epoch 79/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.7630 - acc: 0.6858 - val_loss: 2.9824 - val_acc: 0.2641\n",
      "Epoch 80/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 0.7472 - acc: 0.6913 - val_loss: 3.0537 - val_acc: 0.2616\n",
      "Epoch 81/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.7550 - acc: 0.6891 - val_loss: 3.0130 - val_acc: 0.2606\n",
      "Epoch 82/100\n",
      "15750/15750 [==============================] - 1s 89us/step - loss: 0.7563 - acc: 0.6886 - val_loss: 2.9962 - val_acc: 0.2644\n",
      "Epoch 83/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.7386 - acc: 0.6952 - val_loss: 3.0292 - val_acc: 0.2603\n",
      "Epoch 84/100\n",
      "15750/15750 [==============================] - 2s 100us/step - loss: 0.7417 - acc: 0.6925 - val_loss: 3.0485 - val_acc: 0.2625\n",
      "Epoch 85/100\n",
      "15750/15750 [==============================] - 1s 91us/step - loss: 0.7488 - acc: 0.6891 - val_loss: 3.0202 - val_acc: 0.2648\n",
      "Epoch 86/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.7563 - acc: 0.6845 - val_loss: 3.0370 - val_acc: 0.2610\n",
      "Epoch 87/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 0.7410 - acc: 0.6926 - val_loss: 3.0449 - val_acc: 0.2648\n",
      "Epoch 88/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 0.7445 - acc: 0.6925 - val_loss: 3.0534 - val_acc: 0.2641\n",
      "Epoch 89/100\n",
      "15750/15750 [==============================] - 1s 89us/step - loss: 0.7372 - acc: 0.6914 - val_loss: 3.0727 - val_acc: 0.2644\n",
      "Epoch 90/100\n",
      "15750/15750 [==============================] - 1s 89us/step - loss: 0.7423 - acc: 0.6943 - val_loss: 3.0594 - val_acc: 0.2587\n",
      "Epoch 91/100\n",
      "15750/15750 [==============================] - 1s 91us/step - loss: 0.7402 - acc: 0.6983 - val_loss: 3.0529 - val_acc: 0.2644\n",
      "Epoch 92/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.7347 - acc: 0.6956 - val_loss: 3.0510 - val_acc: 0.2606\n",
      "Epoch 93/100\n",
      "15750/15750 [==============================] - 1s 87us/step - loss: 0.7370 - acc: 0.6971 - val_loss: 3.0698 - val_acc: 0.2619\n",
      "Epoch 94/100\n",
      "15750/15750 [==============================] - 1s 89us/step - loss: 0.7368 - acc: 0.6935 - val_loss: 3.0871 - val_acc: 0.2616\n",
      "Epoch 95/100\n",
      "15750/15750 [==============================] - 1s 89us/step - loss: 0.7262 - acc: 0.6961 - val_loss: 3.0841 - val_acc: 0.2594\n",
      "Epoch 96/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.7323 - acc: 0.7010 - val_loss: 3.0441 - val_acc: 0.2657\n",
      "Epoch 97/100\n",
      "15750/15750 [==============================] - 2s 100us/step - loss: 0.7212 - acc: 0.6990 - val_loss: 3.0867 - val_acc: 0.2625\n",
      "Epoch 98/100\n",
      "15750/15750 [==============================] - 1s 90us/step - loss: 0.7234 - acc: 0.7016 - val_loss: 3.0750 - val_acc: 0.2606\n",
      "Epoch 99/100\n",
      "15750/15750 [==============================] - 1s 88us/step - loss: 0.7282 - acc: 0.6983 - val_loss: 3.1011 - val_acc: 0.2568\n",
      "Epoch 100/100\n",
      "15750/15750 [==============================] - 1s 89us/step - loss: 0.7096 - acc: 0.7066 - val_loss: 3.1267 - val_acc: 0.2622\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(data_train, label_train, \n",
    "                  validation_data=(data_test, label_test), \n",
    "                  nb_epoch=100, \n",
    "                  batch_size=315, \n",
    "                  callbacks=[model_checkpoint,lr_sched ],\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_classes=np.argmax(prediction,axis=1)\n",
    "true_classes=np.argmax(label_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_vel=np.zeros([70,45])\n",
    "true_vel=np.zeros([70,45])\n",
    "for i in range(70):\n",
    "    predicted_vel[i,:]=prediction_classes[i*45:i*45+45]\n",
    "    true_vel[i,:]=true_classes[i*45:i*45+45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=0\n",
    "x=25\n",
    "fig = plt.figure(figsize=[15,15])\n",
    "ax1 = fig.add_subplot(2,3,1)\n",
    "ax1.imshow(predicted_vel.T,aspect='auto',vmin=n,vmax=x)\n",
    "ax1.title.set_text('prediction')\n",
    "ax2 = fig.add_subplot(2,3,2)\n",
    "ax2.imshow(true_vel.T,aspect='auto',vmin=n,vmax=x)\n",
    "ax2.title.set_text('true')\n",
    "ax3 = fig.add_subplot(2,3,3)\n",
    "ax3.imshow(np.abs(predicted_vel.T-true_vel.T),aspect='auto',vmin=n,vmax=x)\n",
    "ax3.title.set_text('abs(prediction-true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
